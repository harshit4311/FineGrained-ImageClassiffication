{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbtcbLfCywot",
        "outputId": "9322c171-2a7c-4c90-cf30-9784f1b25030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf  # For tf.data\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.applications import EfficientNetB0\n",
        "\n",
        "# IMG_SIZE is determined by EfficientNet model choice\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\",],\n",
        "    with_info=True, as_supervised=True\n",
        ")\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
        "\n",
        "# Display a part of the dataset\n",
        "displayImages = 20\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i, (image, label) in enumerate(ds_train.take(displayImages)):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Class: {label.numpy()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xnUUfpc9y6eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# •Dataset Overview:\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "\n",
        "# Number of classes\n",
        "num_classes = ds_info.features[\"label\"].num_classes\n",
        "\n",
        "# Number of images in train and test sets\n",
        "num_train_examples = ds_info.splits[\"train\"].num_examples\n",
        "num_test_examples = ds_info.splits[\"test\"].num_examples\n",
        "\n",
        "# Resolution of images\n",
        "resolution = ds_info.features[\"image\"].shape\n",
        "\n",
        "# Distribution of images across classes\n",
        "train_class_distribution = [0] * num_classes\n",
        "test_class_distribution = [0] * num_classes\n",
        "\n",
        "for image, label in ds_train:\n",
        "    train_class_distribution[label.numpy()] += 1\n",
        "\n",
        "for image, label in ds_test:\n",
        "    test_class_distribution[label.numpy()] += 1\n",
        "\n",
        "# Print the dataset overview\n",
        "print(\"Dataset Overview:\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Number of images in train set: {num_train_examples}\")\n",
        "print(f\"Number of images in test set: {num_test_examples}\")\n",
        "print(f\"Resolution of images: {resolution}\")\n",
        "print(\"Distribution of images across classes (Train Set):\")\n",
        "for i in range(num_classes):\n",
        "    print(f\"Class {i}: {train_class_distribution[i]}\")\n",
        "\n",
        "print(\"Distribution of images across classes (Test Set):\")\n",
        "for i in range(num_classes):\n",
        "    print(f\"Class {i}: {test_class_distribution[i]}\")\n"
      ],
      "metadata": {
        "id": "Dk9v3Ao_OtAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# •Visual Inspection:\n",
        "\n",
        "# No.of examples to inspect per class\n",
        "num_examples_per_class = 5\n",
        "\n",
        "# Class names\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "\n",
        "# Manually inspecting a part of images from each class\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    class_images = [(image, label) for image, label in ds_train if label.numpy() == class_idx]\n",
        "    num_examples = min(num_examples_per_class, len(class_images))\n",
        "\n",
        "    # Display a part of the images for the current class\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    plt.suptitle(f\"Class: {class_name}\")\n",
        "    for i in range(num_examples):\n",
        "        image, _ = class_images[i]\n",
        "        plt.subplot(1, num_examples, i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gdPMY4UyPrcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# •Data Split Analysis:\n",
        "\n",
        "# Class names\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "\n",
        "# Calculating the dog-class distribution\n",
        "def calculate_class_distribution(dataset):\n",
        "    class_distribution = [0] * len(class_names)\n",
        "    for image, label in dataset:\n",
        "        class_distribution[label.numpy()] += 1\n",
        "    return class_distribution\n",
        "\n",
        "# Class distribution for each split\n",
        "train_class_distribution = calculate_class_distribution(ds_train)\n",
        "validation_class_distribution = calculate_class_distribution(ds_validation)\n",
        "test_class_distribution = calculate_class_distribution(ds_test)\n",
        "\n",
        "# Class distribution for each split\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(class_names, train_class_distribution, color='blue', alpha=0.5, label='Train')\n",
        "plt.bar(class_names, validation_class_distribution, color='orange', alpha=0.5, label='Validation', width=0.4)\n",
        "plt.bar(class_names, test_class_distribution, color='green', alpha=0.5, label='Test', width=0.3)\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Class Distribution Across Train, Validation, and Test Splits')\n",
        "plt.xticks(rotation=90)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "gAvMWW3YQaNS",
        "outputId": "9f258af1-8931-41f3-a37f-15aba8bbe285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-a4ae5cfde1b6>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Class distribution for each split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_class_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_class_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mvalidation_class_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_class_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtest_class_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_class_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-a4ae5cfde1b6>\u001b[0m in \u001b[0;36mcalculate_class_distribution\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_class_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclass_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mclass_distribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclass_distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# •Pre-Processing(suppressing unwanted distortions, resizing and/or enhancing important features):\n",
        "\n",
        "# Dataset\n",
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "\n",
        "# Image size for resizing\n",
        "image_size = (128, 128)  # Define the desired image size\n",
        "\n",
        "# Function to pre-process images\n",
        "def preprocess_image(image, label):\n",
        "    # Resize the image to the desired size\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    # Normalize the pixel values to the range [0, 1]\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Apply pre-processing to the dataset\n",
        "ds_train = ds_train.map(preprocess_image)\n",
        "ds_test = ds_test.map(preprocess_image)\n",
        "\n",
        "# Optional: Shuffle and batch the dataset\n",
        "ds_train = ds_train.shuffle(1000).batch(32)\n",
        "ds_test = ds_test.batch(32)"
      ],
      "metadata": {
        "id": "G5_oDWfMRXge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks(Deliverables) :"
      ],
      "metadata": {
        "id": "J40W2E9aSlAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Plot class distribution for the chosen dataset(s). If you are working with different datasets, compare the distributions. Attach your plots and code snippets."
      ],
      "metadata": {
        "id": "ov4ttzIVSxNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset\n",
        "dataset_name = \"stanford_dogs\"\n",
        "ds_train, ds_info = tfds.load(dataset_name, split=\"train\", with_info=True)\n",
        "\n",
        "class_names = ds_info.features[\"label\"].names # Class names\n",
        "\n",
        "# Calculating class distribution\n",
        "def calculate_class_distribution(dataset):\n",
        "    class_distribution = [0] * len(class_names)\n",
        "    for example in dataset:\n",
        "        label = example[\"label\"].numpy()\n",
        "        class_distribution[label] += 1\n",
        "    return class_distribution\n",
        "\n",
        "# Class Distribution for the training set\n",
        "train_class_distribution = calculate_class_distribution(ds_train)\n",
        "\n",
        "rbg_colors = ['red', 'blue', 'green']\n",
        "\n",
        "# Plot class distribution with custom colors\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_names, train_class_distribution, color = rbg_colors)\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Class Distribution in Stanford Dogs Dataset')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gAjuDoxsS1q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Study different categories and plot sample images of some categories. Attach sample images and code snippets."
      ],
      "metadata": {
        "id": "4GfhQObJTmN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all category names\n",
        "for class_name in class_names:\n",
        "    print(class_name)"
      ],
      "metadata": {
        "id": "sY7xbAIvbTn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset\n",
        "dataset_name = \"stanford_dogs\"\n",
        "ds_train, ds_info = tfds.load(dataset_name, split=\"train\", with_info=True)\n",
        "\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "\n",
        "# Function to display one image from each category\n",
        "def display_images(dataset, class_names):\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_images = []\n",
        "        for example in dataset:\n",
        "            if example[\"label\"].numpy() == i:\n",
        "                image = example[\"image\"].numpy().astype(\"uint8\")\n",
        "                class_images.append(image)\n",
        "                break  # Take only one image per class\n",
        "        plt.subplot(4, 5, i + 1)\n",
        "        plt.imshow(class_images[0])\n",
        "        plt.title(class_name)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display one image from each category\n",
        "display_images(ds_train, class_names)"
      ],
      "metadata": {
        "id": "SQzDfMO6TtCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.\n"
      ],
      "metadata": {
        "id": "iS6lA3JdcM_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset\n",
        "dataset_name = \"stanford_dogs\"\n",
        "ds_train, ds_info = tfds.load(dataset_name, split=\"train\", with_info=True)\n",
        "\n",
        "# Example categories to display so we can make out the differences\n",
        "categories_to_display = [\n",
        "    \"n02085620-chihuahua\",\n",
        "    \"n02085936-maltese_dog\",\n",
        "    \"n02086240-shih-tzu\",\n",
        "    \"n02106662-german_shepherd\",\n",
        "    \"n02107142-doberman\",\n",
        "    \"n02108551-tibetan_mastiff\",\n",
        "  ]\n",
        "\n",
        "# Display sample images from each category\n",
        "def display_sample_images(dataset, categories_to_display, num_images_per_category=3):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, category in enumerate(categories_to_display):\n",
        "        class_name = category.split(\"-\")[-1]\n",
        "        class_images = []\n",
        "        for example in dataset:\n",
        "            if example[\"label\"].numpy() == class_names.index(category):\n",
        "                image = example[\"image\"].numpy().astype(\"uint8\")\n",
        "                class_images.append(image)\n",
        "                if len(class_images) == num_images_per_category:\n",
        "                    break\n",
        "        for j, image in enumerate(class_images):\n",
        "            plt.subplot(len(categories_to_display), num_images_per_category, i * num_images_per_category + j + 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(class_name)\n",
        "            plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display sample images from specified categories\n",
        "display_sample_images(ds_train, categories_to_display)"
      ],
      "metadata": {
        "id": "vOG1wrWxcQwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
      ],
      "metadata": {
        "id": "mqhoSS0ny7JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def format_label(label):\n",
        "    string_label = label_info.int2str(label)\n",
        "    return string_label.split(\"-\")[1]\n",
        "\n",
        "\n",
        "label_info = ds_info.features[\"label\"]\n",
        "for i, (image, label) in enumerate(ds_train.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "qT-FMc-Qy9iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_augmentation_layers = [\n",
        "    layers.RandomRotation(factor=0.15),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomFlip(),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "]\n",
        "\n",
        "\n",
        "def img_augmentation(images):\n",
        "    for layer in img_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images\n"
      ],
      "metadata": {
        "id": "EWERkeDLy_d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in ds_train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = img_augmentation(np.expand_dims(image.numpy(), axis=0))\n",
        "        aug_img = np.array(aug_img)\n",
        "        plt.imshow(aug_img[0].astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(format_label(label)))\n",
        "        plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "Mba61Z90zBQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# One-hot / categorical encoding\n",
        "def input_preprocess_train(image, label):\n",
        "    image = img_augmentation(image)\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def input_preprocess_test(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "ds_train = ds_train.map(input_preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(input_preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size=BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "K5twMdvhzD2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNetB0(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    classes=NUM_CLASSES,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        ")\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "epochs = 100  # @param {type: \"slider\", min:10, max:100}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "\n",
        "# the accuracy will increase very slowly and may overfit."
      ],
      "metadata": {
        "id": "khZSlU8AzGHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "id": "ommsih3YzM-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "mg68xl9rzOvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(num_classes=NUM_CLASSES)\n",
        "\n",
        "epochs = 8  # @param {type: \"slider\", min:8, max:80}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "id": "02qRufzZzQl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "epochs = 4  =\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "id": "HZ37IYs_zSL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before Augmentation"
      ],
      "metadata": {
        "id": "a08yXh6XYKOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
        "    with_info=True, as_supervised=True\n",
        ")\n",
        "\n",
        "# Display a part of the dataset\n",
        "displayImages = 20\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i, (image, label) in enumerate(ds_train.take(displayImages)):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Class: {label.numpy()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eq-FhExSZhU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After Augmentation"
      ],
      "metadata": {
        "id": "egb21V44ZrKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in ds_train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = img_augmentation(np.expand_dims(image.numpy(), axis=0))\n",
        "        aug_img = np.array(aug_img)\n",
        "        plt.imshow(aug_img[0].astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(format_label(label)))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "ar90vnCdZzKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Comments on how Augmentation could help the learning process of the neural. networks.\n",
        "\n",
        "#### - Augmentation will help diversify the dataset by applying different procedures on images like rotation, flipping, adjusting thhe contrast, etc.\n",
        "\n",
        "#### - This would help the model learn to recognise objects from different perspectives, improving its performance on real-world data."
      ],
      "metadata": {
        "id": "rjbOOKxrZ8Hg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks - Layers and Parameter"
      ],
      "metadata": {
        "id": "RU_rDZmWdJXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNetB0(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    classes=NUM_CLASSES,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        ")\n",
        "\n",
        "model.summary() # Print"
      ],
      "metadata": {
        "id": "17COzcGMdgyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary with serial numbers so its easy to get the no.of layers\n",
        "def print_summary_with_serialNumber(model):\n",
        "    layer_number = 0\n",
        "    for layer in model.layers:\n",
        "        layer_number += 1\n",
        "        print(f\"{layer_number}. {layer.name} ({layer.__class__.__name__})\")\n",
        "        print(f\"   {layer.output_shape[1:]}\")\n",
        "        param_count = layer.count_params()\n",
        "        print(f\"   Trainable params: {param_count}\")\n",
        "        print()\n",
        "\n",
        "# Print\n",
        "print_summary_with_serialNumber(model)"
      ],
      "metadata": {
        "id": "INlZaGFqemCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvNext Model"
      ],
      "metadata": {
        "id": "JCvs9p_NOfza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "# Define ConvNetX model\n",
        "def ConvNetX(input_shape, num_classes, dropout_rate=0.5, num_filters=32):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(num_filters*2, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(num_filters*4, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Custom wrapper for ConvNetX model to use with GridSearchCV\n",
        "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_shape, num_classes, dropout_rate=0.5, num_filters=32, epochs=10, batch_size=64):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_filters = num_filters\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = ConvNetX(self.input_shape, self.num_classes, self.dropout_rate, self.num_filters)\n",
        "        self.model.compile(optimizer='adam',\n",
        "                           loss='sparse_categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.model.predict(X), axis=1)\n",
        "\n",
        "# Load dataset\n",
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"],\n",
        "    with_info=True, as_supervised=True\n",
        ")\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Define hyperparameters grid for grid search\n",
        "param_grid = {\n",
        "    'dropout_rate': [0.2, 0.3, 0.5],\n",
        "    'num_filters': [32, 64, 128],\n",
        "}\n",
        "\n",
        "# Create KerasClassifierWrapper for GridSearchCV\n",
        "model = KerasClassifierWrapper(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES, epochs=10, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Perform grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(ds_train.batch(BATCH_SIZE))\n",
        "\n",
        "# Get best parameters\n",
        "best_params = grid_result.best_params_\n",
        "best_model = grid_result.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in ds_test.batch(BATCH_SIZE):\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(best_model.predict(images))\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "C8FNYqkRXGNn",
        "outputId": "d340afe9-d82a-4629-97ad-a18b7788187b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Singleton array array(<_BatchDataset element_spec=(TensorSpec(shape=(None, None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n      dtype=object) cannot be considered a valid collection.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a0e81d78b787>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Perform grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Get best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             )\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array array(<_BatchDataset element_spec=(TensorSpec(shape=(None, None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n      dtype=object) cannot be considered a valid collection."
          ]
        }
      ]
    }
  ]
}